#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµå¼è¾“å‡ºæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€çš„ stream=True å‚æ•°è·å¾—å®æ—¶å“åº”
"""
import asyncio
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from minion import config
from minion.main.brain import Brain
from minion.main.local_python_env import LocalPythonEnv
from minion.providers import create_llm_provider
from minion.agents.base_agent import BaseAgent

async def demo_brain_stream():
    """æ¼”ç¤º Brain çš„æµå¼è¾“å‡º"""
    print("=== Brain æµå¼è¾“å‡ºæ¼”ç¤º ===")
    
    # é…ç½®æ¨¡å‹
    model = "gpt-4o-mini"
    llm_config = config.models.get(model)
    llm = create_llm_provider(llm_config)
    
    # åˆ›å»º Brain
    brain = Brain(llm=llm)
    
    # æµå¼è¾“å‡ºç¤ºä¾‹
    print("é—®é¢˜: è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
    print("æµå¼å›ç­”:")
    print("-" * 50)
    
    result = await brain.step(
        query="è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬å…¶ä¸»è¦ç±»å‹å’Œåº”ç”¨åœºæ™¯ï¼Ÿ", 
        route="cot",  # ä½¿ç”¨ Chain of Thought è·å¾—æ›´è¯¦ç»†çš„å›ç­”
        stream=True   # å¯ç”¨æµå¼è¾“å‡º
    )
    
    print("-" * 50)
    print(f"æœ€ç»ˆç­”æ¡ˆ: {result.answer}")

async def demo_agent_stream():
    """æ¼”ç¤º Agent çš„æµå¼è¾“å‡º"""
    print("\n=== Agent æµå¼è¾“å‡ºæ¼”ç¤º ===")
    
    # åˆ›å»º Agent
    agent = BaseAgent(name="demo_agent")
    
    async with agent:  # ä½¿ç”¨ context manager è‡ªåŠ¨ setup å’Œ cleanup
        print("é—®é¢˜: è§£é‡Šæ·±åº¦å­¦ä¹ çš„å·¥ä½œåŸç†")
        print("Agent æµå¼å›ç­”:")
        print("-" * 50)
        
        # ä½¿ç”¨ Agent çš„æµå¼åŠŸèƒ½ - è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨
        stream_generator = await agent.run_async(
            task="è¯·è§£é‡Šæ·±åº¦å­¦ä¹ çš„å·¥ä½œåŸç†ï¼ŒåŒ…æ‹¬ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ¦‚å¿µ",
            stream=True,  # å¯ç”¨æµå¼è¾“å‡º
            route="cot"   # ä½¿ç”¨è¯¦ç»†æ¨ç†
        )
        
        # å¤„ç†æµå¼ç»“æœ
        final_result = None
        async for result in stream_generator:
            print(f"æ­¥éª¤: {str(result)[:100]}...")
            final_result = result
            if hasattr(result, 'terminated') and result.terminated:
                break
        
        print("-" * 50)
        print(f"Agent æœ€ç»ˆç»“æœ: {final_result}")

async def demo_comparison():
    """å¯¹æ¯”æ™®é€šæ¨¡å¼å’Œæµå¼æ¨¡å¼"""
    print("\n=== æ™®é€šæ¨¡å¼ vs æµå¼æ¨¡å¼å¯¹æ¯” ===")
    
    model = "gpt-4o-mini"
    llm_config = config.models.get(model)
    llm = create_llm_provider(llm_config)
    brain = Brain(llm=llm)
    
    query = "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬10é¡¹ï¼Œå¹¶è§£é‡Šè®¡ç®—è¿‡ç¨‹"
    
    # æ™®é€šæ¨¡å¼
    print("1. æ™®é€šæ¨¡å¼ (stream=False):")
    print("ç­‰å¾…å®Œæ•´å“åº”...")
    result_normal = await brain.step(
        query=query,
        route="cot",
        stream=False
    )
    print(f"æ™®é€šæ¨¡å¼ç»“æœ: {result_normal.answer}")
    
    print("\n2. æµå¼æ¨¡å¼ (stream=True):")
    print("å®æ—¶æ˜¾ç¤ºå“åº”:")
    print("-" * 30)
    result_stream = await brain.step(
        query=query,
        route="cot", 
        stream=True
    )
    print("-" * 30)
    print(f"æµå¼æ¨¡å¼ç»“æœ: {result_stream.answer}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Minion ç»Ÿä¸€æµå¼è¾“å‡ºåŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # æ¼”ç¤º Brain æµå¼è¾“å‡º
        await demo_brain_stream()
        
        # æ¼”ç¤º Agent æµå¼è¾“å‡º
        await demo_agent_stream()
        
        # å¯¹æ¯”æ¼”ç¤º
        await demo_comparison()
        
        print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("- ç»Ÿä¸€ä½¿ç”¨ stream=True å‚æ•°å¯ç”¨æµå¼è¾“å‡º")
        print("- Brain.step() ç›´æ¥è¿”å›ç»“æœ")
        print("- Agent.run_async() è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œéœ€è¦ç”¨ async for å¤„ç†")
        print("- æµå¼è¾“å‡ºä¼šå®æ—¶æ˜¾ç¤º LLM çš„å“åº”è¿‡ç¨‹")
        print("- é€‚ç”¨äºéœ€è¦å®æ—¶åé¦ˆçš„äº¤äº’å¼åº”ç”¨")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())