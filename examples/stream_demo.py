#!/usr/bin/env python3
"""
æµå¼è¾“å‡ºæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Minion ç³»ç»Ÿçš„çœŸæ­£æµå¼è¾“å‡ºåŠŸèƒ½
"""
import asyncio
import os
import time
from datetime import datetime
from minion import config
from minion.main.brain import Brain
from minion.main.input import Input
from minion.providers import create_llm_provider

class StreamDemo:
    """æµå¼è¾“å‡ºæ¼”ç¤ºç±»"""
    
    def __init__(self, model_name="gpt-4o"):
        """åˆå§‹åŒ–æ¼”ç¤º"""
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹é…ç½®
        self.model_name = model_name
        self.llm_config = config.models.get(model_name)
        
        if not self.llm_config:
            print(f"âŒ æ¨¡å‹ {model_name} åœ¨é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°")
            print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
            for name in config.models.keys():
                print(f"   - {name}")
            raise ValueError(f"Model {model_name} not found in config")
        
        # åˆ›å»º LLM æä¾›è€…å’Œ Brain
        self.llm = create_llm_provider(self.llm_config)
        self.brain = Brain(llm=self.llm)
        
        print("ğŸš€ æµå¼è¾“å‡ºæ¼”ç¤ºåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“‹ ä½¿ç”¨æ¨¡å‹: {model_name}")
        print(f"ğŸ”§ API ç±»å‹: {self.llm_config.api_type}")
        print(f"ğŸ”‘ é…ç½®çŠ¶æ€: å·²ä» config.yaml åŠ è½½")
        print("-" * 60)

    async def demo_basic_streaming(self):
        """åŸºç¡€æµå¼è¾“å‡ºæ¼”ç¤º"""
        print("\nğŸ”¥ åŸºç¡€æµå¼è¾“å‡ºæ¼”ç¤º")
        print("=" * 50)
        
        # åˆ›å»ºæµå¼è¾“å…¥
        input_data = Input(
            query="è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼ŒåŒ…æ‹¬å…¶å†å²å‘å±•ã€ä¸»è¦æŠ€æœ¯å’Œåº”ç”¨é¢†åŸŸ",
            stream=True  # å¯ç”¨æµå¼è¾“å‡º
        )
        
        print(f"ğŸ“ æŸ¥è¯¢: {input_data.query}")
        print("ğŸ”„ å¼€å§‹æµå¼è¾“å‡º:")
        print("-" * 50)
        
        start_time = time.time()
        chunk_count = 0
        total_chars = 0
        
        try:
            # ä½¿ç”¨ Brain è¿›è¡Œæµå¼è¾“å‡º
            stream_generator = await self.brain.step({"input": input_data})
            
            async for chunk in stream_generator:
                # å¤„ç† StreamChunk å¯¹è±¡æˆ–å­—ç¬¦ä¸²
                if hasattr(chunk, 'content'):
                    content = chunk.content
                else:
                    content = str(chunk)
                
                # å®æ—¶è¾“å‡ºæ¯ä¸ªå—
                print(content, end='', flush=True)
                chunk_count += 1
                total_chars += len(content)
                
                # æ·»åŠ å°å»¶è¿Ÿä»¥æ›´å¥½åœ°å±•ç¤ºæµå¼æ•ˆæœ
                await asyncio.sleep(0.01)
            
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"\n{'-' * 50}")
            print(f"âœ… æµå¼è¾“å‡ºå®Œæˆ!")
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   - æ€»å—æ•°: {chunk_count}")
            print(f"   - æ€»å­—ç¬¦æ•°: {total_chars}")
            print(f"   - è€—æ—¶: {duration:.2f} ç§’")
            print(f"   - å¹³å‡é€Ÿåº¦: {total_chars/duration:.1f} å­—ç¬¦/ç§’")
            
        except Exception as e:
            print(f"\nâŒ æµå¼è¾“å‡ºå¤±è´¥: {e}")

    async def demo_different_minions(self):
        """ä¸åŒ Minion çš„æµå¼è¾“å‡ºæ¼”ç¤º"""
        print("\nğŸ¤– ä¸åŒ Minion æµå¼è¾“å‡ºå¯¹æ¯”")
        print("=" * 50)
        
        # æµ‹è¯•ä¸åŒçš„ minion ç±»å‹
        test_cases = [
            {
                "name": "RawMinion",
                "route": None,  # ä½¿ç”¨é»˜è®¤è·¯ç”±é€‰æ‹©
                "query": "ç®€å•ä»‹ç»ä¸€ä¸‹ Python ç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹",
                "description": "åŸå§‹ Minionï¼Œç›´æ¥ä¸ LLM äº¤äº’"
            },
            {
                "name": "CotMinion", 
                "route": "cot",
                "query": "è¯·ä¸€æ­¥æ­¥åˆ†æä¸ºä»€ä¹ˆ Python é€‚åˆåˆå­¦è€…å­¦ä¹ ç¼–ç¨‹",
                "description": "æ€ç»´é“¾ Minionï¼Œé€æ­¥æ¨ç†"
            },
            {
                "name": "NativeMinion",
                "route": "native", 
                "query": "Python åœ¨æ•°æ®ç§‘å­¦é¢†åŸŸæœ‰å“ªäº›ä¼˜åŠ¿ï¼Ÿ",
                "description": "åŸç”Ÿ Minionï¼Œä½¿ç”¨æ ‡å‡†æç¤ºæ¨¡æ¿"
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ” æµ‹è¯• {i}/{len(test_cases)}: {test_case['name']}")
            print(f"ğŸ“ æè¿°: {test_case['description']}")
            print(f"â“ æŸ¥è¯¢: {test_case['query']}")
            print("ğŸ”„ æµå¼è¾“å‡º:")
            print("-" * 40)
            
            # åˆ›å»ºè¾“å…¥
            input_data = Input(
                query=test_case['query'],
                stream=True,
                route=test_case['route']
            )
            
            start_time = time.time()
            chunk_count = 0
            
            try:
                stream_generator = await self.brain.step({"input": input_data})
                
                async for chunk in stream_generator:
                    # å¤„ç† StreamChunk å¯¹è±¡æˆ–å­—ç¬¦ä¸²
                    if hasattr(chunk, 'content'):
                        content = chunk.content
                    else:
                        content = str(chunk)
                    
                    print(content, end='', flush=True)
                    chunk_count += 1
                    await asyncio.sleep(0.01)
                
                duration = time.time() - start_time
                print(f"\nâœ… {test_case['name']} å®Œæˆ ({chunk_count} å—, {duration:.1f}s)")
                
            except Exception as e:
                print(f"\nâŒ {test_case['name']} å¤±è´¥: {e}")

    async def demo_streaming_vs_normal(self):
        """æµå¼è¾“å‡º vs æ™®é€šè¾“å‡ºå¯¹æ¯”æ¼”ç¤º"""
        print("\nâš–ï¸  æµå¼è¾“å‡º vs æ™®é€šè¾“å‡ºå¯¹æ¯”")
        print("=" * 50)
        
        query = "è¯·è¯¦ç»†ä»‹ç»æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œä¸»è¦ç®—æ³•ç±»å‹"
        
        # æµ‹è¯•æµå¼è¾“å‡º
        print("ğŸ”„ æµå¼è¾“å‡ºæµ‹è¯•:")
        print("-" * 30)
        
        input_stream = Input(
            query=query,
            stream=True,
            route="cot"
        )
        
        stream_start = time.time()
        stream_chunks = []
        
        try:
            stream_generator = await self.brain.step({"input": input_stream})
            
            async for chunk in stream_generator:
                # å¤„ç† StreamChunk å¯¹è±¡æˆ–å­—ç¬¦ä¸²
                if hasattr(chunk, 'content'):
                    content = chunk.content
                else:
                    content = str(chunk)
                
                print(content, end='', flush=True)
                stream_chunks.append(content)
                await asyncio.sleep(0.01)
            
            stream_duration = time.time() - stream_start
            stream_result = ''.join(stream_chunks)
            
            print(f"\nğŸ“Š æµå¼è¾“å‡ºç»Ÿè®¡:")
            print(f"   - å—æ•°: {len(stream_chunks)}")
            print(f"   - æ€»é•¿åº¦: {len(stream_result)} å­—ç¬¦")
            print(f"   - è€—æ—¶: {stream_duration:.2f} ç§’")
            
        except Exception as e:
            print(f"\nâŒ æµå¼è¾“å‡ºå¤±è´¥: {e}")
            stream_result = ""
            stream_duration = 0
        
        # æµ‹è¯•æ™®é€šè¾“å‡º
        print(f"\nğŸ”„ æ™®é€šè¾“å‡ºæµ‹è¯•:")
        print("-" * 30)
        
        input_normal = Input(
            query=query,
            stream=False,  # ç¦ç”¨æµå¼è¾“å‡º
            route="cot"
        )
        
        normal_start = time.time()
        
        try:
            normal_result = await self.brain.step({"input": input_normal})
            normal_duration = time.time() - normal_start
            
            # è¾“å‡ºç»“æœ
            if hasattr(normal_result, 'answer'):
                print(normal_result.answer)
                normal_text = normal_result.answer
            else:
                print(str(normal_result))
                normal_text = str(normal_result)
            
            print(f"\nğŸ“Š æ™®é€šè¾“å‡ºç»Ÿè®¡:")
            print(f"   - æ€»é•¿åº¦: {len(normal_text)} å­—ç¬¦")
            print(f"   - è€—æ—¶: {normal_duration:.2f} ç§’")
            
        except Exception as e:
            print(f"\nâŒ æ™®é€šè¾“å‡ºå¤±è´¥: {e}")
            normal_duration = 0
            normal_text = ""
        
        # å¯¹æ¯”ç»“æœ
        print(f"\nğŸ“ˆ å¯¹æ¯”ç»“æœ:")
        print(f"   - æµå¼è¾“å‡º: {len(stream_result)} å­—ç¬¦, {stream_duration:.2f}s")
        print(f"   - æ™®é€šè¾“å‡º: {len(normal_text)} å­—ç¬¦, {normal_duration:.2f}s")
        if stream_duration > 0 and normal_duration > 0:
            print(f"   - é€Ÿåº¦å¯¹æ¯”: æµå¼ {len(stream_result)/stream_duration:.1f} vs æ™®é€š {len(normal_text)/normal_duration:.1f} å­—ç¬¦/ç§’")

    async def demo_interactive_streaming(self):
        """äº¤äº’å¼æµå¼è¾“å‡ºæ¼”ç¤º"""
        print("\nğŸ’¬ äº¤äº’å¼æµå¼è¾“å‡ºæ¼”ç¤º")
        print("=" * 50)
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºæ¼”ç¤º")
        print("è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        print("-" * 50)
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_query = input("\nğŸ¤” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if user_query.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if user_query.lower() == 'help':
                    print("ğŸ“‹ å¯ç”¨å‘½ä»¤:")
                    print("   - ç›´æ¥è¾“å…¥é—®é¢˜è¿›è¡Œæµå¼å¯¹è¯")
                    print("   - 'quit' æˆ– 'exit': é€€å‡ºæ¼”ç¤º")
                    print("   - 'help': æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
                    continue
                
                if not user_query:
                    print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜")
                    continue
                
                # åˆ›å»ºæµå¼è¾“å…¥
                input_data = Input(
                    query=user_query,
                    stream=True,
                    route="cot"  # ä½¿ç”¨æ€ç»´é“¾æ¨ç†
                )
                
                print(f"\nğŸ¤– AI å›ç­”:")
                print("-" * 30)
                
                start_time = time.time()
                chunk_count = 0
                
                # æµå¼è¾“å‡ºå›ç­”
                stream_generator = await self.brain.step({"input": input_data})
                
                async for chunk in stream_generator:
                    # å¤„ç† StreamChunk å¯¹è±¡æˆ–å­—ç¬¦ä¸²
                    if hasattr(chunk, 'content'):
                        content = chunk.content
                    else:
                        content = str(chunk)
                    
                    print(content, end='', flush=True)
                    chunk_count += 1
                    await asyncio.sleep(0.01)
                
                duration = time.time() - start_time
                print(f"\n{'-' * 30}")
                print(f"ğŸ“Š ({chunk_count} å—, {duration:.1f}s)")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºæ¼”ç¤º")
                break
            except Exception as e:
                print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")

    async def demo_advanced_features(self):
        """é«˜çº§åŠŸèƒ½æ¼”ç¤º"""
        print("\nğŸš€ é«˜çº§æµå¼è¾“å‡ºåŠŸèƒ½æ¼”ç¤º")
        print("=" * 50)
        
        # æ¼”ç¤ºå¸¦ç³»ç»Ÿæç¤ºçš„æµå¼è¾“å‡º
        print("ğŸ­ å¸¦ç³»ç»Ÿæç¤ºçš„æµå¼è¾“å‡º:")
        print("-" * 40)
        
        input_data = Input(
            query="è¯·ä»‹ç»ä¸€ä¸‹é‡å­è®¡ç®—çš„åŸºæœ¬åŸç†",
            system_prompt="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç‰©ç†å­¦æ•™æˆï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚çš„ç§‘å­¦æ¦‚å¿µã€‚",
            stream=True,
            route="cot"
        )
        
        try:
            stream_generator = await self.brain.step({"input": input_data})
            
            async for chunk in stream_generator:
                # å¤„ç† StreamChunk å¯¹è±¡æˆ–å­—ç¬¦ä¸²
                if hasattr(chunk, 'content'):
                    content = chunk.content
                else:
                    content = str(chunk)
                
                print(content, end='', flush=True)
                await asyncio.sleep(0.01)
            
            print("\nâœ… ç³»ç»Ÿæç¤ºæ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            print(f"\nâŒ ç³»ç»Ÿæç¤ºæ¼”ç¤ºå¤±è´¥: {e}")

    async def run_all_demos(self):
        """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
        print("ğŸ¯ Minion æµå¼è¾“å‡ºå®Œæ•´æ¼”ç¤º")
        print("=" * 60)
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ£€æŸ¥é…ç½®
        if not self.llm_config:
            print(f"\nâš ï¸  è­¦å‘Š: æ¨¡å‹ {self.model_name} é…ç½®æ— æ•ˆ")
            print("è¯·æ£€æŸ¥ config/config.yaml æ–‡ä»¶")
            return
        
        try:
            # è¿è¡Œå„ç§æ¼”ç¤º
            await self.demo_basic_streaming()
            await self.demo_different_minions()
            await self.demo_streaming_vs_normal()
            await self.demo_advanced_features()
            
            print(f"\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
            print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # è¯¢é—®æ˜¯å¦è¿›è¡Œäº¤äº’å¼æ¼”ç¤º
            try:
                choice = input("\nğŸ¤” æ˜¯å¦è¿›è¡Œäº¤äº’å¼æ¼”ç¤º? (y/n): ").strip().lower()
                if choice in ['y', 'yes', 'æ˜¯']:
                    await self.demo_interactive_streaming()
            except KeyboardInterrupt:
                print("\nğŸ‘‹ æ¼”ç¤ºç»“æŸ")
                
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

async def main():
    """ä¸»å‡½æ•°"""
    # å¯ä»¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
    # å¯ç”¨æ¨¡å‹: gpt-4o, gpt-4o-mini, chatgpt-4o-latest, claude-3.5, llama3.2 ç­‰
    demo = StreamDemo(model_name="gpt-4o")  # ä½¿ç”¨ Azure GPT-4o
    await demo.run_all_demos()

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())