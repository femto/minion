#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®Œæ•´å±•ç¤ºMetaå·¥å…·ç»“æœåº”ç”¨çš„çœŸå®CodeAgentç¤ºä¾‹
"""
import asyncio
from minion.agents.code_agent import CodeAgent
from minion.main.brain import Brain
from minion.main.async_python_executor import AsyncPythonExecutor, evaluate_async_python_code

async def demo_real_world_meta_usage():
    """çœŸå®ä¸–ç•Œçš„Metaå·¥å…·ç»“æœåº”ç”¨ç¤ºä¾‹"""
    print("ğŸŒŸ çœŸå®ä¸–ç•ŒMetaå·¥å…·åº”ç”¨æ¼”ç¤º\n")
    
    # ä¸€ä¸ªçœŸæ­£ä½“ç°Metaå·¥å…·ä»·å€¼çš„ç®—æ³•ä¼˜åŒ–ç¤ºä¾‹
    real_world_code = '''
def adaptive_search_algorithm(data, target, optimization_level="auto"):
    """è‡ªé€‚åº”æœç´¢ç®—æ³• - æ ¹æ®Metaå·¥å…·åˆ†æé€‰æ‹©æœ€ä¼˜æœç´¢ç­–ç•¥"""
    
    # ğŸ”¥ åˆå§‹æ€è€ƒï¼šåˆ†ææ•°æ®ç‰¹å¾é€‰æ‹©ç®—æ³•
    thinking_result = _meta_call("think", 
        f"éœ€è¦åœ¨{len(data)}ä¸ªå…ƒç´ ä¸­æœç´¢{target}ï¼Œä¼˜åŒ–çº§åˆ«ï¼š{optimization_level}",
        {
            "data_size": len(data),
            "target": str(target),
            "optimization": optimization_level
        },
        "high" if len(data) > 1000 else "medium"
    )
    
    # ğŸ”¥ åˆ©ç”¨æ€è€ƒç»“æœé€‰æ‹©æœç´¢ç­–ç•¥
    search_algorithm = "linear"  # é»˜è®¤
    preprocessing_needed = False
    
    if thinking_result:
        analysis = thinking_result.get("analysis", {})
        complexity = analysis.get("complexity", "medium")
        suggestions = thinking_result.get("suggestions", [])
        
        # æ ¹æ®æ€è€ƒåˆ†æå†³å®šç®—æ³•
        if complexity == "high" and len(data) > 100:
            # å¤æ‚åœºæ™¯ï¼Œå€¼å¾—é¢„å¤„ç†æˆæœ¬
            search_algorithm = "binary"
            preprocessing_needed = True
        elif complexity == "low" or len(data) <= 10:
            # ç®€å•åœºæ™¯ï¼Œç›´æ¥æœç´¢
            search_algorithm = "linear"
        else:
            # ä¸­ç­‰åœºæ™¯ï¼Œè€ƒè™‘æ•°æ®ç‰¹å¾
            if optimization_level == "speed":
                search_algorithm = "binary"
                preprocessing_needed = True
            elif optimization_level == "memory":
                search_algorithm = "linear"
            else:  # auto
                # æ ¹æ®æ•°æ®å¤§å°è‡ªåŠ¨é€‰æ‹©
                search_algorithm = "binary" if len(data) > 50 else "linear"
                preprocessing_needed = search_algorithm == "binary"
        
        # å¦‚æœæœ‰å»ºè®®ï¼Œè¿›ä¸€æ­¥è°ƒæ•´
        if suggestions:
            main_suggestion = suggestions[0].lower()
            if "systematic" in main_suggestion and not preprocessing_needed:
                search_algorithm = "binary"
                preprocessing_needed = True
    
    # ğŸ”¥ åˆ¶å®šæ‰§è¡Œè®¡åˆ’
    plan_steps = ["æ•°æ®é¢„å¤„ç†", "æ‰§è¡Œæœç´¢", "éªŒè¯ç»“æœ"] if preprocessing_needed else ["æ‰§è¡Œæœç´¢", "éªŒè¯ç»“æœ"]
    
    plan_result = _meta_call("plan", "create", {
        "title": f"{search_algorithm}æœç´¢ç®—æ³•æ‰§è¡Œ",
        "algorithm": search_algorithm,
        "preprocessing": preprocessing_needed,
        "steps": plan_steps,
        "expected_complexity": "O(log n)" if search_algorithm == "binary" else "O(n)"
    })
    
    execution_mode = "optimized"
    if plan_result:
        total_steps = plan_result.get("total_steps", len(plan_steps))
        if total_steps > 3:
            execution_mode = "comprehensive"
        elif total_steps < 3:
            execution_mode = "minimal"
    
    # æ‰§è¡Œæœç´¢
    steps_completed = 0
    search_result = None
    
    # æ­¥éª¤1: é¢„å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if preprocessing_needed:
        # æ’åºä»¥æ”¯æŒäºŒåˆ†æœç´¢
        sorted_data = sorted(enumerate(data), key=lambda x: x[1])
        sorted_values = [item[1] for item in sorted_data]
        
        _meta_call("plan", "complete_step", {
            "result": "æ•°æ®é¢„å¤„ç†å®Œæˆ",
            "notes": f"æ’åº{len(data)}ä¸ªå…ƒç´ ç”¨äºäºŒåˆ†æœç´¢"
        })
        steps_completed += 1
        
        # äºŒåˆ†æœç´¢
        left, right = 0, len(sorted_values) - 1
        position = -1
        
        while left <= right:
            mid = (left + right) // 2
            if sorted_values[mid] == target:
                # æ‰¾åˆ°ç›®æ ‡ï¼Œè·å–åŸå§‹ç´¢å¼•
                position = sorted_data[mid][0]
                break
            elif sorted_values[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        search_result = position
        algorithm_used = "binary_search"
        
    else:
        # çº¿æ€§æœç´¢
        for i, value in enumerate(data):
            if value == target:
                search_result = i
                break
        
        if search_result is None:
            search_result = -1
        
        algorithm_used = "linear_search"
    
    _meta_call("plan", "complete_step", {
        "result": f"æœç´¢å®Œæˆï¼Œç»“æœç´¢å¼•: {search_result}",
        "notes": f"ç®—æ³•: {algorithm_used}"
    })
    steps_completed += 1
    
    # éªŒè¯ç»“æœ
    is_correct = False
    if search_result >= 0 and search_result < len(data):
        is_correct = data[search_result] == target
    elif search_result == -1:
        is_correct = target not in data
    
    _meta_call("plan", "complete_step", {
        "result": f"éªŒè¯{'é€šè¿‡' if is_correct else 'å¤±è´¥'}",
        "notes": f"æ‰¾åˆ°ä½ç½®: {search_result}, æ­£ç¡®æ€§: {is_correct}"
    })
    steps_completed += 1
    
    # ğŸ”¥ åæ€ç®—æ³•é€‰æ‹©å’Œæ€§èƒ½
    reflection_result = _meta_call("reflect", "decision", {
        "algorithm_chosen": search_algorithm,
        "preprocessing_used": preprocessing_needed,
        "data_characteristics": {
            "size": len(data),
            "target_found": search_result >= 0
        },
        "performance_factors": {
            "steps_completed": steps_completed,
            "execution_mode": execution_mode,
            "correctness": is_correct
        },
        "alternatives_considered": ["linear_search", "binary_search"]
    })
    
    # ğŸ”¥ åˆ©ç”¨åæ€ç»“æœè¯„ä¼°ç®—æ³•é€‰æ‹©è´¨é‡
    choice_quality = "good"
    efficiency_score = 0.8
    
    if reflection_result:
        learning_points = reflection_result.get("learning_points", [])
        recommendations = reflection_result.get("recommendations", [])
        
        # æ ¹æ®åæ€è¯„ä¼°é€‰æ‹©è´¨é‡
        if preprocessing_needed and len(data) < 20:
            choice_quality = "over_engineered"
            efficiency_score = 0.6
        elif not preprocessing_needed and len(data) > 100:
            choice_quality = "sub_optimal"
            efficiency_score = 0.7
        elif is_correct and steps_completed <= len(plan_steps):
            choice_quality = "excellent"
            efficiency_score = 0.9
        
        # å¦‚æœæœ‰å¤ªå¤šå»ºè®®ï¼Œè¯´æ˜é€‰æ‹©æœ‰é—®é¢˜
        if len(recommendations) > 2:
            efficiency_score -= 0.1
    
    return {
        "target": target,
        "found_at_index": search_result,
        "algorithm_used": search_algorithm,
        "preprocessing_used": preprocessing_needed,
        "steps_completed": steps_completed,
        "execution_mode": execution_mode,
        "correctness": is_correct,
        "choice_quality": choice_quality,
        "efficiency_score": efficiency_score,
        "thinking_influenced_choice": thinking_result is not None,
        "plan_guided_execution": plan_result is not None,
        "reflection_provided_feedback": reflection_result is not None
    }

# ğŸ”¥ æµ‹è¯•ç”¨ä¾‹ - å±•ç¤ºä¸åŒåœºæ™¯ä¸‹Metaå·¥å…·å¦‚ä½•å½±å“ç®—æ³•é€‰æ‹©
test_cases = [
    {
        "name": "å°æ•°æ®é›†",
        "data": [3, 1, 4, 1, 5, 9, 2, 6],
        "target": 5,
        "optimization": "auto"
    },
    {
        "name": "ä¸­ç­‰æ•°æ®é›†",
        "data": list(range(1, 51)),  # 1åˆ°50
        "target": 25,
        "optimization": "speed"
    },
    {
        "name": "å¤§æ•°æ®é›†", 
        "data": list(range(1, 201)),  # 1åˆ°200
        "target": 150,
        "optimization": "auto"
    },
    {
        "name": "ç›®æ ‡ä¸å­˜åœ¨",
        "data": [10, 20, 30, 40, 50],
        "target": 35,
        "optimization": "memory"
    }
]

for i, test_case in enumerate(test_cases, 1):
    result = adaptive_search_algorithm(
        test_case["data"], 
        test_case["target"], 
        test_case["optimization"]
    )
    
    print(f"\\næµ‹è¯• {i}: {test_case['name']}")
    print(f"æ•°æ®é‡: {len(test_case['data'])}, ç›®æ ‡: {test_case['target']}")
    print(f"ç»“æœ: ç´¢å¼• {result['found_at_index']} ({'æ‰¾åˆ°' if result['found_at_index'] >= 0 else 'æœªæ‰¾åˆ°'})")
    print(f"ç®—æ³•: {result['algorithm_used']}")
    print(f"é¢„å¤„ç†: {'æ˜¯' if result['preprocessing_used'] else 'å¦'}")
    print(f"æ‰§è¡Œæ¨¡å¼: {result['execution_mode']}")
    print(f"é€‰æ‹©è´¨é‡: {result['choice_quality']}")
    print(f"æ•ˆç‡è¯„åˆ†: {result['efficiency_score']:.1f}")
    print(f"Metaå·¥å…·å½±å“: æ€è€ƒ{'âœ“' if result['thinking_influenced_choice'] else 'âœ—'} è®¡åˆ’{'âœ“' if result['plan_guided_execution'] else 'âœ—'} åæ€{'âœ“' if result['reflection_provided_feedback'] else 'âœ—'}")
    print("-" * 60)

print("\\nğŸ¯ å…³é”®å±•ç¤º:")
print("1. ğŸ§  thinking_result.analysis.complexity â†’ ç®—æ³•é€‰æ‹©")
print("2. ğŸ“‹ plan_result.total_steps â†’ æ‰§è¡Œæ¨¡å¼æ§åˆ¶") 
print("3. ğŸ” reflection_result.recommendations â†’ è´¨é‡è¯„ä¼°")
print("4. ğŸ’¡ Metaå·¥å…·ç»“æœç›´æ¥é©±åŠ¨æ‰€æœ‰å…³é”®å†³ç­–!")
'''
    
    print("ğŸ”§ æ‰§è¡ŒçœŸå®ä¸–ç•ŒMetaå·¥å…·åº”ç”¨æ¼”ç¤º...")
    
    # åˆ›å»ºæ‰§è¡Œå™¨
    executor = AsyncPythonExecutor(additional_authorized_imports=[])
    executor.send_tools({})
    
    try:
        result = await evaluate_async_python_code(
            real_world_code,
            static_tools=executor.static_tools,
            custom_tools={},
            state=executor.state.copy(),
            authorized_imports=[]
        )
        print("âœ… çœŸå®ä¸–ç•Œæ¼”ç¤ºæ‰§è¡ŒæˆåŠŸ!")
        print("\nğŸ‰ æ¼”ç¤ºè¦ç‚¹:")
        print("   ğŸ”¥ Metaå·¥å…·ç»“æœç›´æ¥å½±å“ç®—æ³•é€‰æ‹©")
        print("   ğŸ”¥ thinking â†’ é€‰æ‹©linear vs binary search")
        print("   ğŸ”¥ plan â†’ æ§åˆ¶æ‰§è¡Œæ­¥éª¤å’Œæ¨¡å¼")
        print("   ğŸ”¥ reflect â†’ è¯„ä¼°é€‰æ‹©è´¨é‡å’Œæ•ˆç‡")
        print("   ğŸ”¥ å®Œæ•´çš„æ€è€ƒâ†’è§„åˆ’â†’æ‰§è¡Œâ†’åæ€é—­ç¯")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

# æ·»åŠ ä¸€ä¸ªç®€åŒ–çš„ç›´æ¥æµ‹è¯•
async def test_direct_meta_usage():
    """ç›´æ¥æµ‹è¯•Metaå·¥å…·ç»“æœçš„è·å–å’Œä½¿ç”¨"""
    print("\nğŸ§ª ç›´æ¥Metaå·¥å…·ç»“æœæµ‹è¯•\n")
    
    from minion.tools.think_in_code_tool import ThinkInCodeTool
    from minion.tools.meta_tools import PlanTool, ReflectionTool
    
    # ç›´æ¥æµ‹è¯•æ€è€ƒå·¥å…·
    think_tool = ThinkInCodeTool()
    result = await think_tool.forward(
        "æµ‹è¯•å¤æ‚çš„ç®—æ³•é€‰æ‹©é—®é¢˜",
        {"complexity": "high", "domain": "algorithms"},
        "high"
    )
    
    print("ğŸ§  ThinkInCodeTool ç›´æ¥ç»“æœ:")
    print(f"   æ€è€ƒå®Œæˆ: {result.get('thinking_complete')}")
    print(f"   åˆ†æå¤æ‚åº¦: {result.get('analysis', {}).get('complexity')}")
    print(f"   æ€è€ƒç±»å‹: {result.get('analysis', {}).get('thought_type')}")
    print(f"   å»ºè®®æ•°é‡: {len(result.get('suggestions', []))}")
    if result.get('suggestions'):
        print(f"   ä¸»è¦å»ºè®®: {result['suggestions'][0]}")
    
    # æµ‹è¯•è®¡åˆ’å·¥å…·
    plan_tool = PlanTool()
    plan_result = await plan_tool.forward("create", {
        "title": "æµ‹è¯•è®¡åˆ’",
        "steps": ["åˆ†æ", "è®¾è®¡", "å®ç°"]
    })
    
    print(f"\nğŸ“‹ PlanTool ç›´æ¥ç»“æœ:")
    print(f"   è®¡åˆ’åˆ›å»º: {plan_result.get('plan_created')}")
    print(f"   è®¡åˆ’ID: {plan_result.get('plan_id')}")
    print(f"   æ€»æ­¥æ•°: {plan_result.get('total_steps')}")
    
    # æµ‹è¯•åæ€å·¥å…·
    reflect_tool = ReflectionTool()
    reflect_result = await reflect_tool.forward("result", {
        "algorithm": "binary_search",
        "performance": "good"
    })
    
    print(f"\nğŸ” ReflectionTool ç›´æ¥ç»“æœ:")
    print(f"   åæ€å®Œæˆ: {reflect_result.get('reflection_complete')}")
    print(f"   å­¦ä¹ ç‚¹: {len(reflect_result.get('learning_points', []))}")
    print(f"   å»ºè®®æ•°: {len(reflect_result.get('recommendations', []))}")
    
    print(f"\nâœ… æ‰€æœ‰Metaå·¥å…·è¿”å›äº†ç»“æ„åŒ–çš„å¯ç”¨ç»“æœ!")

if __name__ == "__main__":
    asyncio.run(demo_real_world_meta_usage())
    asyncio.run(test_direct_meta_usage())