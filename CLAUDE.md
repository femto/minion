## ğŸ§  **è®°å¿†å­˜å‚¨**

### **ç³»ç»Ÿæ¶æ„è®°å¿†**
- never put test in the top level folder
- agent.run_async() è¿”å›çš„æ˜¯ä¸€ä¸ªasyncå‡½æ•°ï¼Œéœ€è¦å…ˆawaitæ‰èƒ½è·å¾—async generator
  - æ­£ç¡®ç”¨æ³•: `async for event in (await agent.run_async(input_obj, **kwargs)):`
  - é”™è¯¯ç”¨æ³•: `async for event in agent.run_async(input_obj, **kwargs):`
  - è¿™æ˜¯å› ä¸ºrun_asyncæ˜¯asyncå‡½æ•°ï¼Œå®ƒdelegateåˆ°å…¶ä»–å‡½æ•°ï¼Œæœ¬èº«éœ€è¦awaitæ‰èƒ½è¿”å›çœŸæ­£çš„async generator

- StreamChunkæµå¼å¤„ç†æœ€ä½³å®è·µ
  - StreamChunkæ˜¯agentæµå¼è¾“å‡ºçš„åŸºæœ¬å•å…ƒï¼Œæ¯ä¸ªchunkåŒ…å«ä¸€å°éƒ¨åˆ†å†…å®¹ï¼ˆå¦‚å•ä¸ªtokenï¼‰
  - UIå¤„ç†æ—¶åº”è¯¥ç´¯ç§¯StreamChunkå†…å®¹ï¼Œè€Œä¸æ˜¯ä¸ºæ¯ä¸ªchunkåˆ›å»ºå•ç‹¬çš„æ¶ˆæ¯è¡Œ
  - StreamChunkæœ‰ä¸åŒç±»å‹ï¼ˆchunk_typeï¼‰ï¼š
    - 'text': Providerå±‚è¾“å‡ºæ–‡æœ¬ï¼ˆopenai_providerä½¿ç”¨ï¼‰
    - 'tool_call': å·¥å…·è°ƒç”¨ä¿¡æ¯
    - 'tool_response': å·¥å…·å“åº”ç»“æœ
    - 'llm_output': Agentå±‚å¸¸è§„LLMè¾“å‡ºå†…å®¹
    - 'step_start': Agentæ­¥éª¤å¼€å§‹
    - 'step_end': Agentæ­¥éª¤ç»“æŸ
    - 'completion': ä»»åŠ¡å®Œæˆ
    - 'warning': è­¦å‘Šä¿¡æ¯
    - 'error': é”™è¯¯ä¿¡æ¯
    - 'final_answer': æœ€ç»ˆç­”æ¡ˆ
  - ç´¯ç§¯æ¨¡å¼å¤„ç†ï¼š
    ```python
    streaming_content = []
    if isinstance(event, StreamChunk):
        # å¯¹äºtextå’Œllm_outputç±»å‹çš„chunkéœ€è¦ç´¯ç§¯
        if event.chunk_type in ['text', 'llm_output']:
            streaming_content.append(event.content)
            display_content = "".join(streaming_content)
        else:
            # å…¶ä»–ç±»å‹å•ç‹¬å¤„ç†ï¼ˆå¦‚error, final_answerç­‰ï¼‰
            handle_special_chunk(event)
    ```

### **å¼€å‘æµç¨‹è®°å¿†**
- å¦‚æœæ˜¯ä¸€å®šåŠŸèƒ½çš„ä¿®æ”¹çš„è¯,å°½å¯èƒ½æ·»åŠ test,å…ˆè·‘é€štest
- å¦‚æœéå¸¸ç®€å•çš„ä¿®æ”¹å¯ä»¥ä¸ç”¨test
- å¦å¤–æ·»åŠ çš„æ–‡ä»¶è¯·git add åˆ°ç‰ˆæœ¬åº“é‡Œ
- å¦‚æœæ˜¯ä¿®æ”¹examples,ä¹Ÿè¯·æ”¹å®Œä¹‹åè¯•è·‘è¯¥example,ä¿®æ”¹å¿…è¦çš„bug,ç›´åˆ°è·‘é€šä¸ºæ­¢
