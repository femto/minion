from typing import Any, Union, List, Optional, Type
from pydantic import BaseModel
import json
import xml.etree.ElementTree as ET
import re
import random
import inspect

from tenacity import retry, stop_after_attempt, retry_if_exception_type

from minion.configs.config import config
from minion.schema.message_types import Message
from minion.actions.action_node import LLMActionNode
from minion.schema.messages import user
from minion.providers import create_llm_provider
from minion.models.schemas import Answer  # Import the Answer model
from minion.exceptions import FinalAnswerException
from minion.tools.tool_decorator import tool as decorate_tool


def _format_tool_result(tool_name: str, tool_result: Any) -> str:
    """
    Format tool execution result for LLM consumption.

    Args:
        tool_name: Name of the tool
        tool_result: Result from tool execution

    Returns:
        Formatted string for the tool result
    """
    # Special handling for final_answer tool
    if tool_name == 'final_answer':
        if isinstance(tool_result, dict):
            result_str = json.dumps(tool_result, ensure_ascii=False, indent=2)
        else:
            result_str = str(tool_result)
        return f"FINAL_ANSWER:{result_str}"

    # Format the result based on type
    if isinstance(tool_result, dict):
        result_str = json.dumps(tool_result, ensure_ascii=False, indent=2)
    elif isinstance(tool_result, (list, tuple)):
        result_str = json.dumps(tool_result, ensure_ascii=False, indent=2)
    else:
        result_str = str(tool_result)

    return f"Tool {tool_name} execution result:\n{result_str}"


# @ell.complex(model="gpt-4o-mini")
# def ell_call(ret):
#     """You are a helpful assistant."""
#     return ret
class LmpActionNode(LLMActionNode):
    def __init__(self, llm, input_parser=None, output_parser=None):
        super().__init__(llm, input_parser, output_parser)
        #ell.init(**config.ell, default_client=self.llm.client_sync)

    async def execute(self, messages: Union[str, Message, List[Message], dict, List[dict]], response_format: Optional[Union[Type[BaseModel], dict]] = None, output_raw_parser=None, format="json", tools=None, tool_choice="auto", stream=False, stop=None, **kwargs) -> Any:
        # å¤„ç† system_prompt å‚æ•°
        system_prompt = kwargs.pop('system_prompt', None)
        
        # å¤„ç†å¯é€‰çš„ llm å‚æ•°
        selected_llm = kwargs.pop('llm', None)
        current_llm = selected_llm if selected_llm is not None else self.llm
        
        # æ·»åŠ  input_parser å¤„ç†
        if self.input_parser:
            messages = self.input_parser(messages)

        # Convert string/single message to list
        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]
        elif isinstance(messages, Message):
            # Convert Message object to dictionary format
            messages = [messages.model_dump()]
        elif isinstance(messages, dict) and "role" in messages:
            # Single message in dictionary format
            messages = [messages]
        elif isinstance(messages, list) and all(isinstance(msg, Message) for msg in messages):
            # Convert list of Message objects to list of dictionaries
            messages = [msg.model_dump() for msg in messages]

        # å¦‚æœæœ‰ system_promptï¼Œå°†å…¶æ·»åŠ åˆ° messages çš„å¼€å¤´
        if system_prompt:

            # has_system = any(msg.get("role") == "system" for msg in messages)
            # if not has_system:
                messages.insert(0, {"role": "system", "content": system_prompt})

        # å¤„ç† tools å‚æ•°
        if tools is not None:
            # å°† tools è½¬æ¢ä¸º API æ ¼å¼
            tools_formatted = self._format_tools_for_api(tools)
            if tools_formatted:
                api_params = {
                    "temperature": current_llm.config.temperature,
                    "model": current_llm.config.model,
                    "tools": tools_formatted,
                    "tool_choice": tool_choice,
                    "original_tools": tools  # ä¿å­˜åŸå§‹å·¥å…·å¯¹è±¡
                }
            else:
                api_params = {
                    "temperature": current_llm.config.temperature,
                    "model": current_llm.config.model,
                    "original_tools": tools  # ä¿å­˜åŸå§‹å·¥å…·å¯¹è±¡
                }
        else:
            # ä» llm.config è·å–é…ç½®
            api_params = {
                "temperature": current_llm.config.temperature, #+ random.random() * 0.01, #add random to avoid prompt caching
                "model": current_llm.config.model,
            }

        # å¤„ç†stopå‚æ•°
        if stop is not None:
            api_params['stop'] = stop
        
        # å°† kwargs åˆå¹¶åˆ° api_params ä¸­ï¼Œå…è®¸è¦†ç›–é»˜è®¤å€¼
        api_params.update(kwargs)
        
        # å¤„ç†æµå¼å‚æ•°
        if stream:
            api_params['stream'] = True
            
        original_response_format = response_format

        if isinstance(response_format, type) and issubclass(response_format, BaseModel):
            # ç”Ÿæˆ schema
            schema = response_format.model_json_schema()
            schema_with_indent = json.dumps(schema, indent=4)

            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            example = response_format.model_construct()

            if format == "json":
                example_str = example.model_dump_json(indent=4)
                prompt = (
                    f"Please provide the response in JSON format as per the following schema:\n"
                    f"{schema_with_indent}\n\n"
                    f"Here's an example of the expected format:\n"
                    f"{example_str}\n\n"
                    f"Please ensure your response follows this exact schema format."
                )
                api_params['response_format'] = { "type": "json_object" }
            else:  # format == "xml" or format == "xml_simple"
                example_dict = example.model_dump()
                example_xml = self._dict_to_xml_example(example_dict)
                prompt = (
                    f"""Construct an XML response that adheres to the specified schema below.

Schema Structure Example:
{example_xml}

Required JSON Schema Compliance:
{schema_with_indent}

Your response should be:

Well-formed XML: Ensure it follows XML syntax rules.
Schema-compliant: Each element, attribute, and data type must match the JSON schema requirements.
Error-free for Parsing: Escape all special characters and ensure compatibility for JSON conversion.
Provide a final XML structure that aligns seamlessly with both the XML and JSON schema constraints."""
                )
                api_params['response_format'] = { "type": "text" }

            messages.append({"role": "user", "content": prompt})

        # æ ¹æ®æ˜¯å¦æµå¼è°ƒç”¨ä¸åŒçš„æ–¹æ³•
        if stream:
            # æµå¼æ¨¡å¼ï¼šè¿”å›å¼‚æ­¥ç”Ÿæˆå™¨ï¼ˆå·¥å…·è°ƒç”¨åœ¨ç”Ÿæˆå™¨å†…éƒ¨å¤„ç†ï¼‰
            return self._execute_stream_generator(messages, selected_llm=selected_llm, **api_params)
        
        # éæµå¼æ¨¡å¼
        # æå–å·¥å…·å‚æ•°ï¼ˆä½¿ç”¨åŸå§‹å·¥å…·å¯¹è±¡ï¼‰
        tools = api_params.get('original_tools') or api_params.get('tools')
        
        # åˆ›å»º LLM API å‚æ•°ï¼ˆç§»é™¤å†…éƒ¨å‚æ•°ï¼‰
        llm_api_params = {k: v for k, v in api_params.items() if k != 'original_tools'}
        
        # å¦‚æœæœ‰é€‰å®šçš„LLMï¼Œä¸´æ—¶æ›¿æ¢self.llm
        original_llm = self.llm
        if selected_llm is not None:
            self.llm = selected_llm
        
        try:
            response = await super().execute(messages, **llm_api_params)
        finally:
            # æ¢å¤åŸå§‹LLM
            self.llm = original_llm
        
        # ä» ChatCompletion å¯¹è±¡ä¸­æå–å­—ç¬¦ä¸²å†…å®¹
        if hasattr(response, 'choices') and hasattr(response.choices[0], 'message'):
            message = response.choices[0].message
            if hasattr(message, 'content') and message.content:
                response_text = message.content
            else:
                response_text = ""
        else:
            # å¦‚æœä¸æ˜¯ ChatCompletion å¯¹è±¡ï¼Œå‡è®¾æ˜¯å­—ç¬¦ä¸²
            response_text = str(response)
        
        # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆä»…åœ¨éæµå¼æ¨¡å¼ï¼‰
        if tools is not None:
            response_text = await self._handle_tool_calls(response, tools, messages, llm_api_params)

        if isinstance(response_format, type) and issubclass(response_format, BaseModel):
            if format == "xml" or format == "xml_simple":
                # æ¸…ç†å“åº”ä¸­çš„ä»£ç å—æ ‡è®°
                response_text = response_text.strip()
                if response_text.startswith('```xml'):
                    response_text = response_text[6:]  # ç§»é™¤å¼€å¤´çš„ ```xml
                if response_text.endswith('```'):
                    response_text = response_text[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                response_text = response_text.strip()

                # ç¡®ä¿å“åº”æ˜¯æœ‰æ•ˆçš„ XML
                if not response_text.strip().startswith('<?xml'):
                    response_text = f'<?xml version="1.0" encoding="UTF-8"?>\n{response_text}'

                # æ ¹æ®formaté€‰æ‹©è§£ææ–¹å¼
                if format == "xml_simple":
                    response_text = self._simple_xml_to_json(response_format, response_text)
                else:
                    response_text = self._xml_to_json(response_text)
            response_text = self.normalize_response(response_text)

        if original_response_format and isinstance(original_response_format, type) and issubclass(original_response_format, BaseModel):
            response_text = original_response_format.model_validate_json(response_text)

        if self.output_parser:
            response_text = self.output_parser(response_text)
        return response_text
    
    async def _execute_stream_generator(self, messages, selected_llm=None, **api_params):
        """æµå¼æ‰§è¡Œç”Ÿæˆå™¨ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨"""
        # å¤„ç†å¯é€‰çš„ llm å‚æ•°
        current_llm = selected_llm if selected_llm is not None else self.llm
        
        # æ·»åŠ  input_parser å¤„ç†
        if self.input_parser:
            messages = self.input_parser(messages)

        # Convert string/single message to list
        if isinstance(messages, str):
            messages = [{"role": "user", "content": messages}]
        elif isinstance(messages, Message):
            messages = [messages.model_dump()]
        elif isinstance(messages, dict) and "role" in messages:
            messages = [messages]
        elif isinstance(messages, list) and all(isinstance(msg, Message) for msg in messages):
            messages = [msg.model_dump() for msg in messages]

        # æå–å·¥å…·å‚æ•°ï¼ˆä½¿ç”¨åŸå§‹å·¥å…·å¯¹è±¡ï¼‰
        tools = api_params.get('original_tools') or api_params.get('tools')
        
        # ä½¿ç”¨æµå¼ç”Ÿæˆ
        full_content = ""
        tool_calls = []
        
        # åˆ›å»º LLM API å‚æ•°ï¼ˆç§»é™¤å†…éƒ¨å‚æ•°ï¼‰
        llm_api_params = {k: v for k, v in api_params.items() if k != 'original_tools'}
        
        # ç¡®ä¿stopå‚æ•°è¢«ä¼ é€’
        if 'stop' in api_params:
            llm_api_params['stop'] = api_params['stop']
        
        async for chunk in current_llm.generate_stream(messages, **llm_api_params):
            # å¤„ç† StreamChunk å¯¹è±¡
            if hasattr(chunk, 'content'):
                if chunk.chunk_type == "text":
                    content = chunk.content
                    full_content += content
                    yield chunk  # ç›´æ¥ä¼ é€’æ–‡æœ¬ StreamChunk å¯¹è±¡
                elif chunk.chunk_type == "tool_call":
                    # æ”¶é›†å·¥å…·è°ƒç”¨
                    tool_call = chunk.metadata.get('tool_call')
                    if tool_call:
                        tool_calls.append(tool_call)
                    yield chunk  # ä¼ é€’å·¥å…·è°ƒç”¨ StreamChunk
                    
                    # ç«‹å³æ‰§è¡Œå·¥å…·å¹¶ yield å·¥å…·å“åº”
                    if tool_call:
                        async for response_chunk in self._execute_and_yield_tool_response(tool_call, tools):
                            yield response_chunk
            else:
                # å‘åå…¼å®¹å­—ç¬¦ä¸²
                content = str(chunk)
                full_content += content
                yield content
        
        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œé€’å½’è·å–æœ€ç»ˆå“åº”
        if tools and tool_calls:
            # æ„é€ åŒ…å«å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯
            assistant_message = {
                "role": "assistant",
                "content": full_content if full_content else None,
                "tool_calls": tool_calls
            }
            
            # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨å¹¶è·å–ç»“æœ
            tool_results = []
            for tool_call in tool_calls:
                tool_result = await self._execute_single_tool_call(tool_call, tools)
                tool_results.append(tool_result)

            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† final_answerï¼Œå¦‚æœæ˜¯åˆ™ä¸å†é€’å½’è°ƒç”¨ LLM
            has_final_answer = any(
                tc.get("function", {}).get("name") == "final_answer"
                for tc in tool_calls
            )

            if has_final_answer:
                # final_answer å·²è°ƒç”¨ï¼Œç›´æ¥ç»“æŸï¼Œä¸å†é€’å½’
                return

            # æ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯å’Œç»“æœåˆ°å¯¹è¯å†å²
            updated_messages = messages + [assistant_message] + tool_results

            # é€’å½’è°ƒç”¨è·å–æœ€ç»ˆå“åº”
            async for chunk in self._execute_stream_generator(updated_messages, **api_params):
                yield chunk
        else:
            pass
            # æœ€ç»ˆå¤„ç†
            # if self.output_parser:
            #     full_content = self.output_parser(full_content)
            #
            # # è¿”å›æœ€ç»ˆå®Œæ•´å†…å®¹ä½œä¸ºç‰¹æ®Šæ ‡è®°
            # yield f"[STREAM_COMPLETE: {full_content}]"
    
    async def _execute_and_yield_tool_response(self, tool_call, tools):
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶ç«‹å³ yield å·¥å…·å“åº”"""
        tool_call_id = tool_call.get('id', 'unknown')
        function_name = tool_call.get('function', {}).get('name')
        function_args = tool_call.get('function', {}).get('arguments', '{}')
        
        # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
        tool = self._find_tool(function_name, tools)
        
        if tool:
            try:
                # è§£æå‚æ•°
                import json
                args = json.loads(function_args) if function_args else {}
                
                # æ‰§è¡Œå·¥å…· - ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼
                if hasattr(tool, 'execute'):
                    # ä¼ ç»Ÿçš„ execute æ–¹æ³•
                    result = tool.execute(**args)
                    import asyncio
                    if asyncio.iscoroutine(result):
                        result = await result
                elif callable(tool):
                    # ç›´æ¥è°ƒç”¨å·¥å…·
                    result = tool(**args)
                    import asyncio
                    if asyncio.iscoroutine(result):
                        result = await result
                else:
                    result = f"Error: Tool {function_name} is not callable"
                
                # ç«‹å³ yield å·¥å…·å“åº”
                from minion.main.action_step import StreamChunk

                # Check if this is the final_answer tool
                is_final = function_name == "final_answer"

                tool_response_chunk = StreamChunk(
                    content=f"\nğŸ“Š å·¥å…·æ‰§è¡Œç»“æœ: {str(result)}\n",
                    chunk_type="tool_response" if not is_final else "final_answer",
                    metadata={
                        "tool_call_id": tool_call_id,
                        "tool_name": function_name,
                        "tool_result": str(result)
                    }
                )
                # Set is_final_answer flag for final_answer tool
                if is_final:
                    tool_response_chunk.is_final_answer = True

                yield tool_response_chunk
                
            except Exception as e:
                # å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œä¹Ÿè¦ yield é”™è¯¯å“åº”
                error_msg = f"Error executing {function_name}: {str(e)}"
                
                from minion.main.action_step import StreamChunk
                error_response_chunk = StreamChunk(
                    content=f"\nâŒ å·¥å…·æ‰§è¡Œé”™è¯¯: {error_msg}\n",
                    chunk_type="tool_response",
                    metadata={
                        "tool_call_id": tool_call_id,
                        "tool_name": function_name,
                        "error": str(e)
                    }
                )
                yield error_response_chunk
        else:
            # å·¥å…·æœªæ‰¾åˆ°ï¼Œä¹Ÿè¦ yield é”™è¯¯å“åº”
            error_msg = f"Error: Tool {function_name} not found"
            
            from minion.main.action_step import StreamChunk
            error_response_chunk = StreamChunk(
                content=f"\nâŒ å·¥å…·æœªæ‰¾åˆ°: {function_name}\n",
                chunk_type="tool_response",
                metadata={
                    "tool_call_id": tool_call_id,
                    "tool_name": function_name,
                    "error": error_msg
                }
            )
            yield error_response_chunk
    
    def _find_tool(self, function_name, tools):
        """æŸ¥æ‰¾æŒ‡å®šåç§°çš„å·¥å…·"""
        for tool in tools:
            if hasattr(tool, 'name') and tool.name == function_name:
                return tool
            elif hasattr(tool, 'get_schema'):
                schema = tool.get_schema()
                if schema.get('function', {}).get('name') == function_name:
                    return tool
        return None
    
    async def _execute_single_tool_call(self, tool_call, tools):
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœæ¶ˆæ¯"""
        tool_call_id = tool_call.get('id', 'unknown')
        function_name = tool_call.get('function', {}).get('name')
        function_args = tool_call.get('function', {}).get('arguments', '{}')
        
        # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
        tool = self._find_tool(function_name, tools)
        
        if tool:
            try:
                # è§£æå‚æ•°
                import json
                args = json.loads(function_args) if function_args else {}
                
                # æ‰§è¡Œå·¥å…· - ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼
                if hasattr(tool, 'execute'):
                    # ä¼ ç»Ÿçš„ execute æ–¹æ³•
                    result = tool.execute(**args)
                    import asyncio
                    if asyncio.iscoroutine(result):
                        result = await result
                elif callable(tool):
                    # ç›´æ¥è°ƒç”¨å·¥å…·
                    result = tool(**args)
                    import asyncio
                    if asyncio.iscoroutine(result):
                        result = await result
                else:
                    result = f"Error: Tool {function_name} is not callable"
                
                # åˆ›å»ºå·¥å…·ç»“æœæ¶ˆæ¯
                return {
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "content": str(result)
                }
                
            except Exception as e:
                # å·¥å…·æ‰§è¡Œå¤±è´¥
                error_msg = f"Error executing {function_name}: {str(e)}"
                return {
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "content": error_msg
                }
        else:
            # å·¥å…·æœªæ‰¾åˆ°
            error_msg = f"Error: Tool {function_name} not found"
            return {
                "role": "tool",
                "tool_call_id": tool_call_id,
                "content": error_msg
            }
    
    async def _handle_tool_calls_stream(self, response, tools, messages, api_params):
        """å¤„ç†æµå¼æ¨¡å¼ä¸‹çš„å·¥å…·è°ƒç”¨"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›å“åº”
        # åœ¨æµå¼æ¨¡å¼ä¸‹ï¼Œå·¥å…·è°ƒç”¨ä¼šåœ¨å®Œæ•´å“åº”åå¤„ç†
        return response

    def _dict_to_xml_example(self, data, root_name="root"):
        """Helper method to convert a dictionary to XML example string."""
        if isinstance(data, dict):
            elements = []
            for key, value in data.items():
                elements.append(f"<{key}>{self._dict_to_xml_example(value, key)}</{key}>")
            if root_name == "root":
                return f'<?xml version="1.0" encoding="UTF-8"?>\n<{root_name}>\n  {"  ".join(elements)}\n</{root_name}>'
            return "\n".join(elements)
        elif isinstance(data, list):
            elements = []
            item_name = root_name[:-1] if root_name.endswith('s') else 'item'
            for item in data:
                elements.append(f"<{item_name}>{self._dict_to_xml_example(item, item_name)}</{item_name}>")
            return "\n".join(elements)
        else:
            return str(data) if data is not None else ""

    def _xml_to_json(self, xml_str: str) -> str:
        """Convert XML string to JSON string compatible with Pydantic model."""
        # ç§»é™¤ XML å£°æ˜
        xml_str = re.sub(r'<\?xml[^>]+\?>', '', xml_str).strip()

        # è§£æ XML
        root = ET.fromstring(xml_str)

        # å¦‚æœæ ¹å…ƒç´ æ˜¯ 'root'ï¼Œæˆ‘ä»¬éœ€è¦æå–å…¶å­å…ƒç´ 
        if root.tag == 'root':
            result = {}
            for child in root:
                result[child.tag] = self._process_xml_element(child)
        else:
            result = self._process_xml_element(root)

        return json.dumps(result)

    def _process_xml_element(self, element: ET.Element) -> Any:
        """é€’å½’å¤„ç† XML å…ƒç´ """
        # å¦‚æœå…ƒç´ æ²¡æœ‰å­å…ƒç´ ä¸”æœ‰æ–‡æœ¬
        if len(element) == 0:
            text = element.text.strip() if element.text else ""
            # å°è¯•è½¬æ¢å¸ƒå°”å€¼
            if text.lower() == 'true':
                return True
            elif text.lower() == 'false':
                return False
            # å°è¯•è½¬æ¢æ•°å­—
            try:
                if '.' in text:
                    return float(text)
                return int(text)
            except ValueError:
                return text

        # å¦‚æœå…ƒç´ æœ‰å­å…ƒç´ 
        result = {}
        for child in element:
            # å¤„ç†åˆ—è¡¨æƒ…å†µï¼ˆç›¸åŒæ ‡ç­¾çš„å¤šä¸ªå…ƒç´ ï¼‰
            if child.tag in result:
                if not isinstance(result[child.tag], list):
                    result[child.tag] = [result[child.tag]]
                result[child.tag].append(self._process_xml_element(child))
            else:
                result[child.tag] = self._process_xml_element(child)

        return result

    def _simple_xml_to_json(self, response_format, xml_str: str) -> str:
        """ä½¿ç”¨ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼è§£æXML"""
        # ç§»é™¤XMLå£°æ˜
        xml_str = re.sub(r'<\?xml[^>]+\?>', '', xml_str).strip()

        # è·å–schemaä¸­å®šä¹‰çš„æ‰€æœ‰å­—æ®µ
        schema = response_format.model_json_schema()
        fields = schema.get('properties', {}).keys()

        result = {}
        for field in fields:
            # ä½¿ç”¨éè´ªå©ªåŒ¹é…æ¥æå–æ ‡ç­¾å†…å®¹
            pattern = f"<{field}>(.*?)</{field}>"
            match = re.search(pattern, xml_str, re.DOTALL)
            if match:
                value = match.group(1).strip()
                # å°è¯•è½¬æ¢å¸ƒå°”å€¼
                if value.lower() == 'true':
                    result[field] = True
                elif value.lower() == 'false':
                    result[field] = False
                else:
                    # å°è¯•è½¬æ¢æ•°å­—
                    try:
                        if '.' in value:
                            result[field] = float(value)
                        else:
                            result[field] = int(value)
                    except ValueError:
                        result[field] = value

        return json.dumps(result)
    
    def _format_tools_for_api(self, tools):
        """
        å°†å·¥å…·åˆ—è¡¨è½¬æ¢ä¸ºAPIè°ƒç”¨æ ¼å¼
        
        Args:
            tools: å·¥å…·åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯ BaseTool å®ä¾‹åˆ—è¡¨
            
        Returns:
            list: æ ¼å¼åŒ–åçš„å·¥å…·å®šä¹‰åˆ—è¡¨ï¼Œç¬¦åˆOpenAI APIæ ¼å¼
        """
        if not tools:
            return []
            
        formatted_tools = []
        
        for tool in tools:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ BaseTool å®ä¾‹
            if hasattr(tool, 'name') and hasattr(tool, 'description') and hasattr(tool, 'inputs'):
                tool_def = {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": {
                            "type": "object",
                            "properties": tool.inputs,
                            "required": [
                                name for name, param in tool.inputs.items() 
                                if not param.get("nullable", False)
                            ]
                        }
                    }
                }
                formatted_tools.append(tool_def)
            elif hasattr(tool, 'to_function_spec'):
                # æ”¯æŒ MCP å·¥å…·çš„ to_function_spec æ–¹æ³•
                spec = tool.to_function_spec()
                if isinstance(spec, dict):
                    formatted_tools.append(spec)
            elif hasattr(tool, 'get_schema'):
                # æ”¯æŒæœ‰ get_schema æ–¹æ³•çš„å·¥å…·
                schema = tool.get_schema()
                if isinstance(schema, dict) and "function" in schema:
                    formatted_tools.append(schema)
                elif isinstance(schema, dict) and "type" in schema and schema["type"] == "function":
                    formatted_tools.append(schema)
            elif isinstance(tool, dict) and "function" in tool:
                # å¦‚æœå·²ç»æ˜¯æ­£ç¡®æ ¼å¼çš„å·¥å…·å®šä¹‰
                formatted_tools.append(tool)
            elif callable(tool):
                decorated = decorate_tool(tool)
                tool_def = {
                    "type": "function",
                    "function": {
                        "name": decorated.name,
                        "description": decorated.description,
                        "parameters": {
                            "type": "object",
                            "properties": decorated.inputs,
                            "required": [
                                name for name, param in decorated.inputs.items()
                                if not param.get("nullable", False)
                            ]
                        }
                    }
                }
                formatted_tools.append(tool_def)
                     
        return formatted_tools
    
    async def _handle_tool_calls(self, response, tools, messages, api_params):
        """
        å¤„ç†å·¥å…·è°ƒç”¨å“åº”

        Args:
            response: LLMçš„åŸå§‹å“åº”ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ– ChatCompletion å¯¹è±¡ï¼‰
            tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨
            messages: æ¶ˆæ¯å†å²
            api_params: APIå‚æ•°

        Returns:
            str: å¤„ç†åçš„å“åº”
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯ ChatCompletion å¯¹è±¡
        if hasattr(response, 'choices') and hasattr(response.choices[0], 'message'):
            message = response.choices[0].message
            # æ£€æŸ¥æ˜¯å¦æœ‰ tool_calls
            if hasattr(message, 'tool_calls') and message.tool_calls:
                # å¤„ç† OpenAI æ ¼å¼çš„ tool_calls
                final_response = ""
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    args_str = tool_call.function.arguments

                    # å¦‚æœæ˜¯final_answerï¼Œåˆ™ç›´æ¥æŠ›å‡ºFinalAnswerException
                    if tool_name == 'final_answer':
                        try:
                            import json
                            args_dict = json.loads(args_str) if isinstance(args_str, str) else args_str
                            answer_value = args_dict.get('answer', str(args_dict))
                            raise FinalAnswerException(answer_value)
                        except json.JSONDecodeError:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªå‚æ•°å­—ç¬¦ä¸²
                            raise FinalAnswerException(args_str)

                    # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                    target_tool = None
                    for tool in tools:
                        if hasattr(tool, 'name') and tool.name == tool_name:
                            target_tool = tool
                            break
                        elif hasattr(tool, '__name__') and tool.__name__ == tool_name:
                            target_tool = tool
                            break

                    if target_tool:
                        try:
                            if callable(target_tool):
                                # æ™®é€šå¯è°ƒç”¨å¯¹è±¡
                                if isinstance(args_str,str):
                                    import json
                                    try:
                                        args_dict = json.loads(args_str)
                                        tool_result = target_tool(**args_dict)
                                    except:
                                        args_str.strip().strip('"\'')
                                        args_dict = json.loads(args_str)
                                        tool_result = target_tool(**args_dict)
                                else:
                                    tool_result = target_tool(**args_str) #assume it's dict

                                # æ£€æŸ¥æ˜¯å¦æ˜¯ awaitableï¼Œå¦‚æœæ˜¯åˆ™ await
                                if inspect.iscoroutine(tool_result):
                                    tool_result = await tool_result
                            else:
                                tool_result = "Tool call failed: tool is not callable"

                            final_response += _format_tool_result(tool_name, tool_result) + "\n"

                        except FinalAnswerException as e:
                            # ç‰¹æ®Šå¤„ç† FinalAnswerException
                            final_response += f"FINAL_ANSWER:{e.answer}\n"
                        except Exception as e:
                            error_msg = f"Tool {tool_name} execution error: {str(e)}"
                            final_response += error_msg + "\n"

                return final_response.strip()
            else:
                # æ²¡æœ‰ tool_callsï¼Œè¿”å›æ­£å¸¸å†…å®¹
                return message.content or ""

        # å¦‚æœä¸æ˜¯ ChatCompletion å¯¹è±¡ï¼ŒæŒ‰åŸæ¥çš„å­—ç¬¦ä¸²å¤„ç†æ–¹å¼
        import json
        import re

        # æå–å“åº”æ–‡æœ¬å†…å®¹ç”¨äºæ­£åˆ™åŒ¹é…
        response_text = str(response) if not isinstance(response, str) else response

        # é¦–å…ˆå°è¯•è§£æ XML æ ¼å¼çš„å·¥å…·è°ƒç”¨
        xml_tool_call_pattern = r'<tool_call>\s*<tool_name>(\w+)</tool_name>\s*<parameters>(.*?)</parameters>\s*</tool_call>'
        xml_matches = re.finditer(xml_tool_call_pattern, response_text, re.IGNORECASE | re.DOTALL)

        final_response = response_text
        
        # å¤„ç† XML æ ¼å¼çš„å·¥å…·è°ƒç”¨
        for match in xml_matches:
            tool_name = match.group(1)
            parameters_xml = match.group(2).strip()
            
            # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
            target_tool = None
            for tool in tools:
                if hasattr(tool, 'name') and tool.name == tool_name:
                    target_tool = tool
                    break
                elif hasattr(tool, '__name__') and tool.__name__ == tool_name:
                    target_tool = tool
                    break
            
            if target_tool:
                try:
                    # è§£æå‚æ•°
                    if hasattr(target_tool, 'forward'):
                        # BaseTool å®ä¾‹ï¼Œä»XMLä¸­æå–å‚æ•°
                        if parameters_xml.strip():
                            # ä»XMLä¸­æå–å‚æ•°å€¼
                            # å¦‚æœæ˜¯final_answerï¼Œåˆ™ç›´æ¥æŠ›å‡ºFinalAnswerExceptionï¼Œä¸è°ƒç”¨forward
                            if tool_name == 'final_answer':
                                # ç‰¹æ®Šå¤„ç† final_answer å·¥å…·
                                answer_match = re.search(r'<answer>(.*?)</answer>', parameters_xml, re.DOTALL)
                                if answer_match:
                                    answer_value = answer_match.group(1).strip()
                                    # ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸è°ƒç”¨ forward
                                    raise FinalAnswerException(answer_value)
                                else:
                                    # ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸è°ƒç”¨ forward
                                    raise FinalAnswerException(parameters_xml)
                            else:
                                # å…¶ä»–å·¥å…·çš„å‚æ•°è§£æ
                                tool_result = target_tool.forward(parameters_xml)
                        else:
                            tool_result = target_tool.forward()
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ awaitableï¼Œå¦‚æœæ˜¯åˆ™ await
                        if inspect.iscoroutine(tool_result):
                            tool_result = await tool_result
                    else:
                        tool_result = "Tool call failed: tool is not callable"

                    # æ›¿æ¢å“åº”ä¸­çš„å·¥å…·è°ƒç”¨ä¸ºå·¥å…·ç»“æœ
                    final_response = final_response.replace(
                        match.group(0),
                        _format_tool_result(tool_name, tool_result)
                    )

                except FinalAnswerException as e:
                    # ç‰¹æ®Šå¤„ç† FinalAnswerException
                    final_response = final_response.replace(
                        match.group(0),
                        f"FINAL_ANSWER:{e.answer}"
                    )
                except Exception as e:
                    error_msg = f"Tool {tool_name} execution error: {str(e)}"
                    final_response = final_response.replace(match.group(0), error_msg)

        # ç„¶åå°è¯•è§£æä¼ ç»Ÿçš„å‡½æ•°è°ƒç”¨æ¨¡å¼
        tool_call_pattern = r'(?:è°ƒç”¨å·¥å…·|ä½¿ç”¨å·¥å…·|call tool|use tool).*?(\w+)\s*\((.*?)\)'
        matches = re.finditer(tool_call_pattern, final_response, re.IGNORECASE | re.DOTALL)
        
        for match in matches:
            tool_name = match.group(1)
            args_str = match.group(2)
            
            # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
            target_tool = None
            for tool in tools:
                if hasattr(tool, 'name') and tool.name == tool_name:
                    target_tool = tool
                    break
                elif hasattr(tool, '__name__') and tool.__name__ == tool_name:
                    target_tool = tool
                    break
            
            if target_tool:
                try:
                    # è§£æå‚æ•°
                    if hasattr(target_tool, 'forward'):
                        # BaseTool å®ä¾‹
                        if args_str.strip():
                            # å°è¯•è§£æä¸ºå­—ç¬¦ä¸²å‚æ•°
                            args_str = args_str.strip().strip('"\'')
                            tool_result = target_tool.forward(args_str)
                        else:
                            tool_result = target_tool.forward()
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ awaitableï¼Œå¦‚æœæ˜¯åˆ™ await
                        if inspect.iscoroutine(tool_result):
                            tool_result = await tool_result
                            
                    elif callable(target_tool):
                        # æ™®é€šå¯è°ƒç”¨å¯¹è±¡
                        if args_str.strip():
                            args_str = args_str.strip().strip('"\'')
                            tool_result = target_tool(args_str)
                        else:
                            tool_result = target_tool()
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ awaitableï¼Œå¦‚æœæ˜¯åˆ™ await
                        if inspect.iscoroutine(tool_result):
                            tool_result = await tool_result
                    else:
                        tool_result = "Tool call failed: tool is not callable"

                    # æ›¿æ¢å“åº”ä¸­çš„å·¥å…·è°ƒç”¨ä¸ºå·¥å…·ç»“æœ
                    final_response = final_response.replace(
                        match.group(0),
                        _format_tool_result(tool_name, tool_result)
                    )

                except FinalAnswerException as e:
                    # ç‰¹æ®Šå¤„ç† FinalAnswerException
                    final_response = final_response.replace(
                        match.group(0),
                        f"FINAL_ANSWER:{e.answer}"
                    )
                except Exception as e:
                    error_msg = f"Tool {tool_name} execution error: {str(e)}"
                    final_response = final_response.replace(match.group(0), error_msg)
        
        return final_response
